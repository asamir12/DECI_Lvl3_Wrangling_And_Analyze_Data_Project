{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Summary Report\n",
    "\n",
    "**produced by:** Abdalrahman Samir\n",
    "**Project:** Wrangling and Analyze Data\n",
    "\n",
    "## Overview\n",
    "\n",
    "This report summarizes the data wrangling activities I have done in this project to prepare and clean the following datasets: `twitter-archive-enhanced.csv`, `image-predictions.tsv` and `tweet_json.txt` for use in wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. The project involved gathering, assessing, cleaning, and analyzing Twitter data to create a high-quality dataset for analysis. The primary objective was to transform raw, inconsistent, and incomplete data into a structured, clean, and ready for analysis format.\n",
    "\n",
    "## Data Gathering\n",
    "Three primary data sources were collected:\n",
    "\n",
    "1. **Twitter Archive (Direct Download)**\n",
    "   - File: `twitter_archive_enhanced.csv`\n",
    "   - Contains basic tweet information and dog ratings\n",
    "\n",
    "2. **Image Predictions (Downloaded via Requests)**\n",
    "   - TSV file hosted on Udacity servers\n",
    "   - Contains machine learning predictions about dog breeds in images\n",
    "\n",
    "3. **Additional Tweet Data (via Twitter API)**\n",
    "   - JSON data containing engagement metrics (retweets, favorites)\n",
    "   - Stored in `tweet_json.txt` and processed into `tweet_data.csv`\n",
    "\n",
    "\n",
    "## Data Assessment\n",
    "\n",
    "### Quality Issues Identified:\n",
    "1. Missing values in reply/retweet columns (irrelevant for original content)\n",
    "2. Tweets without images (2297/2356 had images)\n",
    "3. Presence of retweets (181 instances)\n",
    "4. Inaccurate dog names (placeholders like \"a\", \"an\", \"the\", \"None\")\n",
    "5. Incorrect data type (tweet_id as integer)\n",
    "6. Incorrect data type (timestamp as string)\n",
    "7. Useless retweet_status_id column after filtering\n",
    "8. Non-dog images in predictions (543/2075 images)\n",
    "\n",
    "### Tidiness Issues Identified:\n",
    "1. Dog stage information spread across four columns (doggo, floofer, pupper, puppo)\n",
    "2. Data spread across three separate tables: `twitter_archive_clean`, `image_preds_clean` and `tweets_data_clean`\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "### Quality Issues Addressed:\n",
    "1. **Dropped irrelevant columns** (reply/retweet metadata)\n",
    "2. **Removed tweets without images** (kept 2297 entries)\n",
    "3. **Filtered out retweets** (final 2117 original tweets)\n",
    "4. **Standardized dog names** (replaced placeholders with \"Unknown\")\n",
    "5. **Corrected data type** (Converted tweet_id to string)\n",
    "6. **Corrected data type** (Converted timestamp to datetime)\n",
    "7. **Dropped retweet_status_id column**\n",
    "8. **Filtered non-dog images** (kept 1532 dog predictions)\n",
    "\n",
    "### Tidiness Issues Addressed:\n",
    "1. **Consolidated dog stages** into single \"dog_stage\" column\n",
    "2. **Merged the three datasets** into one master dataset: `df_combined`\n",
    "\n",
    "## Storage\n",
    "The final cleaned dataset was saved as `twitter_archive_master.csv` containing:\n",
    "- Original tweet data\n",
    "- Image prediction data\n",
    "- Engagement metrics (from: the `tweet_data.csv`)\n",
    "- Cleaned/standardized columns\n",
    "\n",
    "**Attachments:**  \n",
    "- `twitter_archive_master.csv` (cleaned dataset)\n",
    "- Jupyter Notebook with full wrangling process\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
